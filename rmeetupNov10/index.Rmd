title       : caret package - a brief demonstration 
subtitle    : Denver R Meetup
author      : Matthew Pocernich
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
github:
    user: mjpdenver
    repo: test
---
# Outline

1. Overview of caret
2. Demonstration
3. Examining options

--- 

## What is the issue?

1.  Hundreds of prediction tools [ See Machine Learing Task Page](https://cran.r-project.org/web/views/MachineLearning.html)
2.  Machine learning - practically, not theoretically - what works best
3.  Modes can be subtlely - or not so subtley different in syntax.
4.  Integrating input and output to make comparisons can be challenging.

----

## The data ([Wisconsin Breast Cancer Data- UCI Repo](https://archive.ics.uci.edu/ml/) )

```{r global_options, include=FALSE}
knitr::opts_chunk$set(  warning=FALSE, message=FALSE)
```
 
```{r dataRead, echo=FALSE}

library(plyr)
library(caret)
dat <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data", header = FALSE, sep = ",", as.is = TRUE)

# 1. Sample code number            id number
# 2. Clump Thickness               1 - 10
# 3. Uniformity of Cell Size       1 - 10
# 4. Uniformity of Cell Shape      1 - 10
# 5. Marginal Adhesion             1 - 10
# 6. Single Epithelial Cell Size   1 - 10
# 7. Bare Nuclei                   1 - 10
# 8. Bland Chromatin               1 - 10
# 9. Normal Nucleoli               1 - 10
# 10. Mitoses                       1 - 10
# 11. Class:                        (2 for benign, 4 for malignant)


dat$V7 <- as.integer(dat$V7)
dat <- na.omit(dat)

dat <- dat[,-1] ## drop id row
names(dat) <- c("clump_thick", "unif_size", "unif_shape", "unif_adhesion", "epi_size", "bare_nuc", "bland_chrom", "norm_nucleoli", "mitosis", "class")
dat$class <- as.character(dat$class)
dat$class <- plyr::mapvalues(x =  dat$class, from=c("2", "4"), c("benign","malignant") )
dat$class <- as.factor(dat$class)


i <- sample(x = 1:nrow(dat), size = nrow(dat)/3,replace = FALSE)
dat_train <- dat[-i,]
dat_test <- dat[i, ]

dat_test

```

---

## Random Forest Model
```{r executeRF, echo=TRUE}

library(randomForest)

rf <- randomForest( class ~., dat_train)
print(rf)

```

---

## Random Forest Model - extract and summarize test data prediction

```{r sumRF, echo=TRUE}

mod_rf_pred <- predict(rf, newdata = dat_test)
out_put = data.frame( class = dat_test$class, predicted = mod_rf_pred)

x<- table(out_put)
confusionMatrix(x)

```


--

## Try something else - Naive Bayes Classifier

```{r naiveBayes, warning=FALSE }
library(klaR)

mod_nb <- NaiveBayes( class ~., data = dat)
mod_nb_pred <- predict( mod_nb) ## r

out_put = data.frame( class = dat$class, nb_pred = mod_nb_pred$class)

x<- table(out_put)
confusionMatrix(x)

````

---

## One more - Boosted Classification

```{r ada }
library(ada)

mod_ada <- ada( class ~., data = dat_train)
mod_ada_pred <- predict( mod_ada, dat_test) #, newdata = dat, type = "decision" ) ## r

out_put = data.frame( class = dat_test$class, predicted = mod_ada_pred)

x<- table(out_put)
confusionMatrix(x)

```

---

## Which is best? 

Yuck - we have somework to do.
* Output vary
* Track training and test data
* Create graphics with new datasets.

---

## caret - Random Forest Model

```{r caretRF, echo = TRUE}

fitControl <- trainControl(classProbs = TRUE,## 10-fold CV
     method = "cv",
     number = 10)

set.seed(825)
rf_caret <- train(class ~ ., data = dat_train,
                 method = "rf",
                trControl = trainControl(method = "cv"),  
                 verbose = FALSE)

```

---

## Random Forest Output

```{r rf_caret_out}
rf_caret
#rf_caret_p <- predict(rf_caret,newdata = dat_test)

#confusionMatrix(table(dat_test$class,rf_caret_p))

```

---

## Boosted Classification - caret
### note - this takes a while because there are three tuning parameters

```{r caretada}

set.seed(825)
ada_caret <- train(class ~ ., data = dat_train,
                 method = "ada",
                trControl = trainControl(method = "cv"), 
                 verbose = FALSE) 

```

---

## Boosted Classification Output

```{r ada_caret_output}
ada_caret

```


## Boosted Classification - Parameter Selection Output

```{r ada_caret_graphic, echo=TRUE}
ggplot(ada_caret)

```


---

## Naive Bayes - caret

```{r caretNaiveBayes}

set.seed(825)
nb_caret <- train(class ~ ., data = dat_train,
                 method = "nb",
                trControl = trainControl(method = "cv"),  ## outline methods
#                 trControl = fitControl,
                 verbose = FALSE) ### what does metric mean? What does it do?


nb_caret_p <- predict(nb_caret,newdata = dat_test)

confusionMatrix(table(dat_test$class,nb_caret_p))

```


---

### Compare Models

```{r combine}

resamps <- resamples(list(RF = rf_caret,
                          NB = nb_caret,
                          ADA = ada_caret))
resamps
summary(resamps)


bwplot(resamps, layout = c(3, 1))



difValues <- diff(resamps)
difValues
summary(difValues)

bwplot(difValues, layout = c(3, 1))

```


---

## trainControl - training options

>1. Type of cross validation
>2. number, number of folds in crossvalidation.
>3. selectionFunction - defaults to accuracy.
>4. allowParallel - looks interesting.

---

## train options

>1. method (see list of models)
>2. tuning grid, tunelength or fixed values.
>3. preProcess data - center and scaling

---

## Revisit random forest

```{r rf_revisited}
require(pROC)

rocGrid <-  expand.grid(mtry = c(2,3,4,6,8))

fitControl <- trainControl(classProbs = TRUE,## 10-fold CV
     method = "cv",
     number = 10, 
     summaryFunction = twoClassSummary)

set.seed(825)
rf_caret <- train(class ~ ., data = dat_train,
                 method = "rf",
                trControl = fitControl,  
                 verbose = FALSE,
                metric = "ROC",
                tuneGrid = rocGrid) ### what does metric mean? What does it do?


rf_caret_p <- predict(rf_caret,newdata = dat_test)

confusionMatrix(table(dat_test$class,rf_caret_p))

ggplot(rf_caret)

```


---

### Preprossesing  Tools

1. Impute missing values
2. Center and scale
3. Identify Correlated Predictors (findCorrelation)
4. Identify near zero covariance  (nearZeroVar)
5. Find linear dependancies (findLinearCombos)
6. Transformation and Distance Matrices



